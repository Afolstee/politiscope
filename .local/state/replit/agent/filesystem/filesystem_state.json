{"file_contents":{"analyzer.py":{"content":"import spacy\nimport nltk\nfrom textblob import TextBlob\nimport pandas as pd\nimport re\nfrom collections import Counter\nfrom typing import Dict, List, Tuple\nimport logging\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport json\n\n# Try to download required NLTK data, but don't fail if network is unavailable\ntry:\n    nltk.data.find('tokenizers/punkt')\nexcept LookupError:\n    try:\n        nltk.download('punkt')\n    except Exception:\n        logging.warning(\"Could not download NLTK punkt tokenizer\")\n\ntry:\n    nltk.data.find('corpora/stopwords')\nexcept LookupError:\n    try:\n        nltk.download('stopwords')\n    except Exception:\n        logging.warning(\"Could not download NLTK stopwords\")\n\ntry:\n    nltk.data.find('taggers/averaged_perceptron_tagger')\nexcept LookupError:\n    try:\n        nltk.download('averaged_perceptron_tagger')\n    except Exception:\n        logging.warning(\"Could not download NLTK POS tagger\")\n\nclass PoliticalAnalyzer:\n    def __init__(self):\n        try:\n            self.nlp = spacy.load(\"en_core_web_sm\")\n        except OSError:\n            logging.warning(\"spaCy model not found. Some features may be limited.\")\n            self.nlp = None\n        \n        # Try to load NLTK stopwords, use fallback if not available\n        try:\n            self.stop_words = set(nltk.corpus.stopwords.words('english'))\n        except (LookupError, OSError):\n            # Fallback list of common English stopwords\n            self.stop_words = {\n                'a', 'an', 'and', 'are', 'as', 'at', 'be', 'by', 'for', 'from',\n                'has', 'he', 'in', 'is', 'it', 'its', 'of', 'on', 'that', 'the',\n                'to', 'was', 'will', 'with', 'the', 'this', 'but', 'they', 'have',\n                'had', 'what', 'said', 'each', 'which', 'their', 'time', 'if',\n                'up', 'out', 'many', 'then', 'them', 'these', 'so', 'some', 'her',\n                'would', 'make', 'like', 'into', 'him', 'has', 'two', 'more',\n                'very', 'what', 'know', 'just', 'first', 'get', 'over', 'think',\n                'also', 'your', 'work', 'life', 'only', 'can', 'still', 'should',\n                'after', 'being', 'now', 'made', 'before', 'here', 'through',\n                'when', 'where', 'how', 'all', 'during', 'there', 'our', 'his'\n            }\n            logging.warning(\"Using fallback stopwords list\")\n        \n        # Political rhetoric indicators\n        self.ethos_words = [\n            'experience', 'leadership', 'trust', 'integrity', 'credibility',\n            'expertise', 'qualified', 'proven', 'record', 'accomplished'\n        ]\n        \n        self.pathos_words = [\n            'hope', 'fear', 'anger', 'love', 'hate', 'pride', 'shame',\n            'joy', 'sadness', 'worry', 'concern', 'passion', 'emotion'\n        ]\n        \n        self.logos_words = [\n            'evidence', 'statistics', 'facts', 'data', 'research', 'study',\n            'analysis', 'proof', 'therefore', 'because', 'thus', 'consequently'\n        ]\n        \n        self.rhetorical_devices = {\n            'alliteration': r'\\b([a-zA-Z])\\w*\\s+\\1\\w*',\n            'repetition': r'\\b(\\w+)\\b.*\\b\\1\\b',\n            'metaphor': r'\\b(is|are|was|were)\\s+(a|an|the)?\\s*\\w+',\n            'contrast': r'\\b(but|however|although|while|whereas)\\b'\n        }\n\n    def clean_text(self, text: str) -> str:\n        \"\"\"Clean and preprocess text\"\"\"\n        # Remove extra whitespace and newlines\n        text = re.sub(r'\\s+', ' ', text)\n        # Remove special characters but keep punctuation\n        text = re.sub(r'[^\\w\\s\\.\\!\\?\\,\\;\\:]', '', text)\n        return text.strip()\n\n    def analyze_sentiment(self, text: str) -> Dict:\n        \"\"\"Analyze sentiment using TextBlob\"\"\"\n        try:\n            text = self.clean_text(text)\n            blob = TextBlob(text)\n            \n            # Overall sentiment\n            polarity = blob.sentiment.polarity\n            subjectivity = blob.sentiment.subjectivity\n            \n            # Classify overall sentiment\n            if polarity > 0.1:\n                overall_sentiment = 'Positive'\n            elif polarity < -0.1:\n                overall_sentiment = 'Negative'\n            else:\n                overall_sentiment = 'Neutral'\n            \n            # Sentence-level analysis\n            sentences = blob.sentences\n            sentence_sentiments = []\n            \n            for sentence in sentences[:10]:  # Limit to first 10 sentences\n                sent_polarity = sentence.sentiment.polarity\n                sentence_sentiments.append({\n                    'text': str(sentence),\n                    'polarity': sent_polarity\n                })\n            \n            # Create sentiment distribution\n            positive_count = len([s for s in sentence_sentiments if s['polarity'] > 0.1])\n            negative_count = len([s for s in sentence_sentiments if s['polarity'] < -0.1])\n            neutral_count = len(sentence_sentiments) - positive_count - negative_count\n            \n            total_sentences = len(sentence_sentiments)\n            sentiment_distribution = {\n                'positive': round((positive_count / total_sentences * 100), 1) if total_sentences > 0 else 0,\n                'neutral': round((neutral_count / total_sentences * 100), 1) if total_sentences > 0 else 0,\n                'negative': round((negative_count / total_sentences * 100), 1) if total_sentences > 0 else 0\n            }\n            \n            # Create visualization data\n            viz_data = {\n                'sentiment_chart': {\n                    'labels': ['Positive', 'Neutral', 'Negative'],\n                    'values': [sentiment_distribution['positive'], \n                              sentiment_distribution['neutral'], \n                              sentiment_distribution['negative']],\n                    'type': 'pie'\n                }\n            }\n            \n            return {\n                'overall_sentiment': str(overall_sentiment),\n                'polarity': float(round(polarity, 3)),\n                'subjectivity': float(round(subjectivity, 3)),\n                'sentiment_distribution': sentiment_distribution,\n                'sample_sentences': [{'text': str(s['text']), 'polarity': float(s['polarity'])} for s in sentence_sentiments[:5]],\n                'visualization': viz_data\n            }\n            \n        except Exception as e:\n            logging.error(f\"Error in sentiment analysis: {str(e)}\")\n            return {\n                'overall_sentiment': 'Unknown',\n                'polarity': 0,\n                'subjectivity': 0,\n                'sentiment_distribution': {'positive': 0, 'neutral': 100, 'negative': 0},\n                'error': str(e)\n            }\n\n    def analyze_rhetorical_elements(self, text: str) -> Dict:\n        \"\"\"Analyze rhetorical elements (ethos, pathos, logos)\"\"\"\n        try:\n            text = self.clean_text(text.lower())\n            words = text.split()\n            \n            # Count rhetorical indicators\n            ethos_count = sum(1 for word in words if word in self.ethos_words)\n            pathos_count = sum(1 for word in words if word in self.pathos_words)\n            logos_count = sum(1 for word in words if word in self.logos_words)\n            \n            # Find specific indicators\n            ethos_found = [word for word in words if word in self.ethos_words]\n            pathos_found = [word for word in words if word in self.pathos_words]\n            logos_found = [word for word in words if word in self.logos_words]\n            \n            # Detect rhetorical devices\n            devices_found = []\n            for device, pattern in self.rhetorical_devices.items():\n                if re.search(pattern, text, re.IGNORECASE):\n                    devices_found.append(device)\n            \n            # Calculate percentages\n            total_words = len(words)\n            ethos_percentage = round((ethos_count / total_words * 100), 2) if total_words > 0 else 0\n            pathos_percentage = round((pathos_count / total_words * 100), 2) if total_words > 0 else 0\n            logos_percentage = round((logos_count / total_words * 100), 2) if total_words > 0 else 0\n            \n            # Create visualization data\n            viz_data = {\n                'rhetorical_chart': {\n                    'labels': ['Ethos', 'Pathos', 'Logos'],\n                    'values': [ethos_count, pathos_count, logos_count],\n                    'type': 'bar'\n                }\n            }\n            \n            return {\n                'ethos': {\n                    'count': int(ethos_count),\n                    'percentage': float(ethos_percentage),\n                    'indicators': [str(word) for word in list(set(ethos_found))[:10]]\n                },\n                'pathos': {\n                    'count': int(pathos_count),\n                    'percentage': float(pathos_percentage),\n                    'indicators': [str(word) for word in list(set(pathos_found))[:10]]\n                },\n                'logos': {\n                    'count': int(logos_count),\n                    'percentage': float(logos_percentage),\n                    'indicators': [str(word) for word in list(set(logos_found))[:10]]\n                },\n                'rhetorical_devices': [str(device) for device in devices_found],\n                'visualization': viz_data\n            }\n            \n        except Exception as e:\n            logging.error(f\"Error in rhetorical analysis: {str(e)}\")\n            return {\n                'ethos': {'count': 0, 'percentage': 0, 'indicators': []},\n                'pathos': {'count': 0, 'percentage': 0, 'indicators': []},\n                'logos': {'count': 0, 'percentage': 0, 'indicators': []},\n                'rhetorical_devices': [],\n                'error': str(e)\n            }\n\n    def analyze_word_frequency(self, text: str) -> Dict:\n        \"\"\"Analyze word frequency and create word cloud data\"\"\"\n        try:\n            text = self.clean_text(text.lower())\n            words = text.split()\n            \n            # Filter out stop words and short words\n            meaningful_words = [word for word in words \n                              if word not in self.stop_words \n                              and len(word) > 2 \n                              and word.isalpha()]\n            \n            # Count frequencies\n            word_freq = Counter(meaningful_words)\n            top_words = word_freq.most_common(20)\n            \n            # Calculate statistics\n            total_words = len(words)\n            unique_words = len(set(words))\n            vocabulary_richness = round((unique_words / total_words), 3) if total_words > 0 else 0\n            \n            # Create visualization data - ensure all values are JSON serializable\n            labels = [str(word) for word, count in top_words[:10]]\n            values = [int(count) for word, count in top_words[:10]]\n            \n            viz_data = {\n                'word_frequency_chart': {\n                    'labels': labels,\n                    'values': values,\n                    'type': 'bar'\n                },\n                'word_cloud_data': {str(word): int(count) for word, count in top_words[:50]}\n            }\n            \n            # Ensure all data is JSON serializable\n            serializable_top_words = [(str(word), int(count)) for word, count in top_words]\n            \n            return {\n                'top_words': serializable_top_words,\n                'total_words': int(total_words),\n                'unique_words': int(unique_words),\n                'vocabulary_richness': float(vocabulary_richness),\n                'visualization': viz_data\n            }\n            \n        except Exception as e:\n            logging.error(f\"Error in word frequency analysis: {str(e)}\")\n            return {\n                'top_words': [],\n                'total_words': 0,\n                'unique_words': 0,\n                'vocabulary_richness': 0,\n                'error': str(e)\n            }\n\n    def analyze_linguistic_features(self, text: str) -> Dict:\n        \"\"\"Analyze linguistic features like complexity and readability\"\"\"\n        try:\n            text = self.clean_text(text)\n            \n            # Try NLTK tokenizers, use fallback if not available\n            try:\n                sentences = nltk.sent_tokenize(text)\n                words = nltk.word_tokenize(text)\n            except (LookupError, OSError):\n                # Simple fallback tokenization\n                sentences = [s.strip() for s in re.split(r'[.!?]+', text) if s.strip()]\n                words = re.findall(r'\\b\\w+\\b', text)\n            \n            # Basic statistics\n            num_sentences = len(sentences)\n            num_words = len(words)\n            num_chars = len(text)\n            \n            # Average lengths\n            avg_sentence_length = round(num_words / num_sentences, 2) if num_sentences > 0 else 0\n            avg_word_length = round(sum(len(word) for word in words) / num_words, 2) if num_words > 0 else 0\n            \n            # Syllable counting (approximation)\n            def count_syllables(word):\n                word = word.lower()\n                syllables = 0\n                vowels = 'aeiouy'\n                if word[0] in vowels:\n                    syllables += 1\n                for i in range(1, len(word)):\n                    if word[i] in vowels and word[i-1] not in vowels:\n                        syllables += 1\n                if word.endswith('e'):\n                    syllables -= 1\n                if syllables == 0:\n                    syllables = 1\n                return syllables\n            \n            # Flesch Reading Ease Score\n            total_syllables = sum(count_syllables(word) for word in words if word.isalpha())\n            if num_sentences > 0 and num_words > 0:\n                flesch_score = round(206.835 - (1.015 * avg_sentence_length) - (84.6 * (total_syllables / num_words)), 2)\n            else:\n                flesch_score = 0\n            \n            # Readability interpretation\n            if flesch_score >= 90:\n                readability = \"Very Easy\"\n            elif flesch_score >= 80:\n                readability = \"Easy\"\n            elif flesch_score >= 70:\n                readability = \"Fairly Easy\"\n            elif flesch_score >= 60:\n                readability = \"Standard\"\n            elif flesch_score >= 50:\n                readability = \"Fairly Difficult\"\n            elif flesch_score >= 30:\n                readability = \"Difficult\"\n            else:\n                readability = \"Very Difficult\"\n            \n            return {\n                'text_statistics': {\n                    'sentences': int(num_sentences),\n                    'words': int(num_words),\n                    'characters': int(num_chars),\n                    'avg_sentence_length': float(avg_sentence_length),\n                    'avg_word_length': float(avg_word_length)\n                },\n                'readability': {\n                    'flesch_score': float(flesch_score),\n                    'readability_level': str(readability),\n                    'total_syllables': int(total_syllables)\n                }\n            }\n            \n        except Exception as e:\n            logging.error(f\"Error in linguistic analysis: {str(e)}\")\n            return {\n                'text_statistics': {\n                    'sentences': 0,\n                    'words': 0,\n                    'characters': 0,\n                    'avg_sentence_length': 0,\n                    'avg_word_length': 0\n                },\n                'readability': {\n                    'flesch_score': 0,\n                    'readability_level': 'Unknown',\n                    'total_syllables': 0\n                },\n                'error': str(e)\n            }\n","size_bytes":15848},"app.py":{"content":"import os\nimport logging\nimport json\nimport re\nfrom flask import Flask, render_template, request, jsonify, session, redirect, url_for, flash\nfrom flask_sqlalchemy import SQLAlchemy\nfrom sqlalchemy.orm import DeclarativeBase\nfrom werkzeug.middleware.proxy_fix import ProxyFix\nfrom datetime import datetime\nimport uuid\n\nfrom scraper import PoliticalTextScraper\nfrom analyzer import PoliticalAnalyzer\n\nlogging.basicConfig(level=logging.DEBUG)\n\nclass Base(DeclarativeBase):\n    pass\n\ndb = SQLAlchemy(model_class=Base)\n\n# create the app\napp = Flask(__name__)\napp.secret_key = os.environ.get(\"SESSION_SECRET\", \"your-secret-key-here\")\napp.wsgi_app = ProxyFix(app.wsgi_app, x_proto=1, x_host=1)\n\n# configure the database\napp.config[\"SQLALCHEMY_DATABASE_URI\"] = os.environ.get(\"DATABASE_URL\", \"sqlite:///political_discourse.db\")\napp.config[\"SQLALCHEMY_ENGINE_OPTIONS\"] = {\n    \"pool_recycle\": 300,\n    \"pool_pre_ping\": True,\n}\n\n# initialize the app with the extension\ndb.init_app(app)\n\nwith app.app_context():\n    import models\n    db.create_all()\n\n# Initialize analyzer\nanalyzer = PoliticalAnalyzer()\n\n@app.route('/')\ndef index():\n    \"\"\"Main page with politician input form\"\"\"\n    return render_template('index.html')\n\n@app.route('/analyze', methods=['POST'])\ndef analyze():\n    \"\"\"Start analysis process\"\"\"\n    politician_name = request.form.get('politician_name', '').strip()\n    country = request.form.get('country', '').strip()\n    analysis_types = request.form.getlist('analysis_types')\n    \n    if not politician_name:\n        flash('Please enter a politician name', 'error')\n        return redirect(url_for('index'))\n    \n    if not analysis_types:\n        flash('Please select at least one analysis type', 'error')\n        return redirect(url_for('index'))\n    \n    # Create session ID for tracking\n    session_id = str(uuid.uuid4())\n    session['session_id'] = session_id\n    session['politician_name'] = politician_name\n    session['country'] = country\n    session['analysis_types'] = analysis_types\n    \n    return render_template('analysis.html', \n                         politician_name=politician_name,\n                         country=country,\n                         analysis_types=analysis_types,\n                         session_id=session_id)\n\n@app.route('/api/scrape_texts', methods=['POST'])\ndef scrape_texts():\n    \"\"\"API endpoint to scrape political texts\"\"\"\n    try:\n        data = request.get_json()\n        politician_name = data.get('politician_name')\n        country = data.get('country', '')\n        \n        scraper = PoliticalTextScraper()\n        texts = scraper.collect_texts(politician_name, country)\n        \n        # Store in session for analysis - limit content size to avoid session cookie overflow\n        limited_texts = []\n        for text in texts:\n            limited_text = text.copy()\n            # Limit content to 1000 characters per source to avoid session overflow\n            if 'content' in limited_text:\n                limited_text['content'] = limited_text['content'][:1000]\n            limited_texts.append(limited_text)\n        \n        session['collected_texts'] = limited_texts\n        # Also store full texts temporarily in memory for immediate analysis\n        if not hasattr(app, '_temp_texts'):\n            app._temp_texts = {}\n        app._temp_texts[session.get('session_id', 'default')] = texts\n        \n        return jsonify({\n            'success': True,\n            'texts': texts,\n            'total_sources': len(texts),\n            'total_words': sum(len(text['content'].split()) for text in texts)\n        })\n    \n    except Exception as e:\n        logging.error(f\"Error in scrape_texts: {str(e)}\")\n        return jsonify({\n            'success': False,\n            'error': str(e)\n        }), 500\n\n@app.route('/api/analyze_texts', methods=['POST'])\ndef analyze_texts():\n    \"\"\"API endpoint to analyze collected texts\"\"\"\n    try:\n        data = request.get_json()\n        analysis_types = data.get('analysis_types', [])\n        \n        # Try to get full texts from temporary storage first, fallback to session\n        session_id = session.get('session_id', 'default')\n        texts = []\n        \n        if hasattr(app, '_temp_texts') and session_id in app._temp_texts:\n            texts = app._temp_texts[session_id]\n            logging.info(f\"Using full texts from temp storage: {len(texts)} sources\")\n        else:\n            texts = session.get('collected_texts', [])\n            logging.info(f\"Using texts from session: {len(texts)} sources\")\n            \n        if not texts:\n            logging.error(\"No texts found in session or temp storage\")\n            return jsonify({\n                'success': False,\n                'error': 'No texts found. Please scrape texts first.'\n            }), 400\n        \n        # Combine all text content\n        combined_text = ' '.join([text['content'] for text in texts])\n        \n        results = {}\n        \n        if 'sentiment' in analysis_types:\n            results['sentiment'] = analyzer.analyze_sentiment(combined_text)\n        \n        if 'rhetorical' in analysis_types:\n            results['rhetorical'] = analyzer.analyze_rhetorical_elements(combined_text)\n        \n        if 'word_frequency' in analysis_types:\n            results['word_frequency'] = analyzer.analyze_word_frequency(combined_text)\n        \n        if 'linguistic' in analysis_types:\n            results['linguistic'] = analyzer.analyze_linguistic_features(combined_text)\n        \n        # Store results in session with limited content\n        session['analysis_results'] = results\n        \n        # Store limited source breakdown to avoid session overflow\n        limited_breakdown = []\n        for text in texts:\n            limited_source = {\n                'source': text.get('source', 'Unknown'),\n                'word_count': text.get('word_count', 0),\n                'url': text.get('url', '')\n            }\n            limited_breakdown.append(limited_source)\n        session['source_breakdown'] = limited_breakdown\n        \n        # Clean up temp storage\n        if hasattr(app, '_temp_texts') and session_id in app._temp_texts:\n            del app._temp_texts[session_id]\n        \n        return jsonify({\n            'success': True,\n            'results': results\n        })\n    \n    except Exception as e:\n        logging.error(f\"Error in analyze_texts: {str(e)}\")\n        return jsonify({\n            'success': False,\n            'error': str(e)\n        }), 500\n\n@app.route('/results')\ndef results():\n    \"\"\"Display analysis results\"\"\"\n    results = session.get('analysis_results')\n    politician_name = session.get('politician_name')\n    source_breakdown = session.get('source_breakdown', [])\n    \n    if not results:\n        flash('No analysis results found. Please start a new analysis.', 'error')\n        return redirect(url_for('index'))\n    \n    return render_template('results.html',\n                         results=results,\n                         politician_name=politician_name,\n                         source_breakdown=source_breakdown)\n\n@app.route('/detailed_analysis')\ndef detailed_analysis():\n    \"\"\"Display detailed analysis with highlighted texts\"\"\"\n    results = session.get('analysis_results')\n    politician_name = session.get('politician_name')\n    \n    if not results:\n        flash('No analysis results found. Please start a new analysis.', 'error')\n        return redirect(url_for('index'))\n    \n    # Get the original texts for highlighting\n    analyzed_texts = session.get('analyzed_texts_with_highlights', [])\n    \n    # If we don't have highlighted texts, generate them\n    if not analyzed_texts:\n        analyzed_texts = generate_highlighted_texts()\n        session['analyzed_texts_with_highlights'] = analyzed_texts\n    \n    return render_template('detailed_analysis.html',\n                         politician_name=politician_name,\n                         analyzed_texts=analyzed_texts,\n                         demo_mode=session.get('demo_mode', False))\n\ndef generate_highlighted_texts():\n    \"\"\"Generate highlighted text analysis for detailed view\"\"\"\n    try:\n        # Get original texts from session\n        texts = session.get('collected_texts', [])\n        results = session.get('analysis_results', {})\n        \n        analyzed_texts = []\n        \n        for i, text_source in enumerate(texts):\n            content = text_source.get('content', '')\n            \n            # Apply highlighting based on analysis results\n            highlighted_content = highlight_text_content(content, results)\n            \n            analyzed_texts.append({\n                'source': text_source.get('source', f'Source {i+1}'),\n                'url': text_source.get('url', ''),\n                'word_count': len(content.split()),\n                'highlighted_content': highlighted_content\n            })\n        \n        return analyzed_texts\n        \n    except Exception as e:\n        logging.error(f\"Error generating highlighted texts: {str(e)}\")\n        return []\n\ndef highlight_text_content(content, results):\n    \"\"\"Apply highlighting to text content based on analysis results\"\"\"\n    try:\n        # Start with original content\n        highlighted = content\n        \n        # Get keywords for highlighting\n        sentiment_keywords = ['hope', 'change', 'fear', 'anger', 'love', 'hate', 'proud', 'concern']\n        ethos_keywords = ['experience', 'qualified', 'trust', 'believe', 'promise', 'commitment']\n        pathos_keywords = ['family', 'children', 'future', 'dream', 'struggle', 'fight']\n        logos_keywords = ['evidence', 'facts', 'statistics', 'research', 'data', 'study']\n        key_phrases = ['america', 'american', 'democracy', 'freedom', 'justice', 'equality']\n        \n        # Apply highlighting with different classes\n        highlighted = apply_highlights(highlighted, sentiment_keywords, 'sentiment-positive')\n        highlighted = apply_highlights(highlighted, ethos_keywords, 'rhetorical-ethos')\n        highlighted = apply_highlights(highlighted, pathos_keywords, 'rhetorical-pathos')\n        highlighted = apply_highlights(highlighted, logos_keywords, 'rhetorical-logos')\n        highlighted = apply_highlights(highlighted, key_phrases, 'key-phrase')\n        \n        return highlighted\n        \n    except Exception as e:\n        logging.error(f\"Error highlighting content: {str(e)}\")\n        return content\n\ndef apply_highlights(text, keywords, css_class):\n    \"\"\"Apply highlighting to specific keywords in text\"\"\"\n    for keyword in keywords:\n        pattern = re.compile(r'\\b' + re.escape(keyword) + r'\\b', re.IGNORECASE)\n        replacement = f'<span class=\"text-highlight {css_class} annotation\">{keyword}<div class=\"annotation-tooltip\">{css_class.replace(\"-\", \" \").title()}</div></span>'\n        text = pattern.sub(replacement, text)\n    return text\n\n@app.route('/feedback', methods=['GET', 'POST'])\ndef feedback():\n    \"\"\"Handle user feedback\"\"\"\n    if request.method == 'POST':\n        try:\n            session_id = session.get('session_id')\n            politician_name = session.get('politician_name')\n            \n            rating = request.form.get('rating')\n            comments = request.form.get('comments', '')\n            helpful = request.form.get('helpful') == 'yes'\n            \n            # Create feedback record\n            feedback_record = models.Feedback()\n            feedback_record.session_id = session_id\n            feedback_record.politician_name = politician_name\n            feedback_record.rating = int(rating) if rating else None\n            feedback_record.comments = comments\n            feedback_record.helpful = helpful\n            feedback_record.timestamp = datetime.utcnow()\n            \n            db.session.add(feedback_record)\n            db.session.commit()\n            \n            flash('Thank you for your feedback!', 'success')\n            return redirect(url_for('index'))\n            \n        except Exception as e:\n            logging.error(f\"Error saving feedback: {str(e)}\")\n            flash('Error saving feedback. Please try again.', 'error')\n    \n    return render_template('feedback.html',\n                         politician_name=session.get('politician_name'))\n\n@app.route('/api/export/<format>')\ndef export_results(format):\n    \"\"\"Export analysis results\"\"\"\n    try:\n        results = session.get('analysis_results')\n        politician_name = session.get('politician_name')\n        \n        if not results:\n            return jsonify({'error': 'No results to export'}), 400\n        \n        export_data = {\n            'politician_name': politician_name,\n            'analysis_timestamp': datetime.utcnow().isoformat(),\n            'results': results,\n            'source_breakdown': session.get('source_breakdown', [])\n        }\n        \n        if format.lower() == 'json':\n            # Clean politician name for filename\n            safe_name = re.sub(r'[^\\w\\s-]', '', politician_name or 'analysis').replace(' ', '_')\n            response = app.response_class(\n                response=json.dumps(export_data, indent=2, default=str),\n                status=200,\n                mimetype='application/json'\n            )\n            response.headers['Content-Disposition'] = f'attachment; filename=\"{safe_name}_analysis.json\"'\n            return response\n        \n        elif format.lower() == 'csv':\n            # Simple CSV export for basic data\n            import csv\n            import io\n            \n            output = io.StringIO()\n            writer = csv.writer(output)\n            \n            # Write header\n            writer.writerow(['Metric', 'Value', 'Details'])\n            \n            # Write sentiment data if available\n            if 'sentiment' in results:\n                sentiment = results['sentiment']\n                writer.writerow(['Overall Sentiment', sentiment.get('overall_sentiment', 'N/A'), sentiment.get('polarity', 'N/A')])\n            \n            # Write word frequency data if available\n            if 'word_frequency' in results:\n                word_freq = results['word_frequency']\n                for word, count in word_freq.get('top_words', [])[:10]:\n                    writer.writerow(['Top Word', word, count])\n            \n            # Clean politician name for filename\n            safe_name = re.sub(r'[^\\w\\s-]', '', politician_name or 'analysis').replace(' ', '_')\n            response = app.response_class(\n                response=output.getvalue(),\n                status=200,\n                mimetype='text/csv'\n            )\n            response.headers['Content-Disposition'] = f'attachment; filename=\"{safe_name}_analysis.csv\"'\n            return response\n        \n        else:\n            return jsonify({'error': 'Unsupported export format'}), 400\n            \n    except Exception as e:\n        logging.error(f\"Error exporting results: {str(e)}\")\n        return jsonify({'error': str(e)}), 500\n\n@app.route('/demo')\ndef demo():\n    \"\"\"Demo mode with real data for Barack Obama\"\"\"\n    try:\n        # Use real scraping and analysis for demo\n        scraper = PoliticalTextScraper()\n        texts = scraper.collect_texts(\"Barack Obama\", \"USA\")\n        \n        if not texts:\n            # Fallback to sample data if scraping fails\n            texts = scraper.get_sample_texts(\"Barack Obama\")\n        \n        if texts:\n            # Combine all text content\n            combined_text = ' '.join([text['content'] for text in texts])\n            \n            # Run real analysis\n            results = {}\n            results['sentiment'] = analyzer.analyze_sentiment(combined_text)\n            results['rhetorical'] = analyzer.analyze_rhetorical_elements(combined_text)\n            results['word_frequency'] = analyzer.analyze_word_frequency(combined_text)\n            results['linguistic'] = analyzer.analyze_linguistic_features(combined_text)\n            \n            # Store results in session\n            session['analysis_results'] = results\n            session['politician_name'] = 'Barack Obama (Demo - Real Data)'\n            session['source_breakdown'] = texts\n            \n            return render_template('results.html',\n                                 results=results,\n                                 politician_name='Barack Obama (Demo - Real Data)',\n                                 source_breakdown=texts,\n                                 demo_mode=True)\n        else:\n            flash('Unable to collect data for demo. Please try the manual analysis.', 'warning')\n            return redirect(url_for('index'))\n            \n    except Exception as e:\n        logging.error(f\"Error in demo mode: {str(e)}\")\n        # Fallback to sample demo data if real analysis fails\n        demo_results = {\n            'sentiment': {\n                'overall_sentiment': 'Positive',\n                'polarity': 0.15,\n                'subjectivity': 0.45,\n                'sentiment_distribution': {\n                    'positive': 60,\n                    'neutral': 30,\n                    'negative': 10\n                }\n            },\n            'rhetorical': {\n                'ethos': {\n                    'count': 15,\n                    'percentage': 2.1,\n                    'indicators': ['experience', 'leadership', 'trust']\n                },\n                'pathos': {\n                    'count': 22,\n                    'percentage': 3.2,\n                    'indicators': ['hope', 'change', 'together']\n                },\n                'logos': {\n                    'count': 8,\n                    'percentage': 1.1,\n                    'indicators': ['evidence', 'statistics', 'facts']\n                },\n                'rhetorical_devices': ['repetition', 'metaphor', 'alliteration']\n            },\n            'word_frequency': {\n                'top_words': [\n                    ['america', 45],\n                    ['people', 38],\n                    ['change', 32],\n                    ['hope', 28],\n                    ['together', 25]\n                ],\n                'unique_words': 1250,\n                'total_words': 5000,\n                'vocabulary_richness': 0.25\n            }\n        }\n        \n        session['analysis_results'] = demo_results\n        session['politician_name'] = 'Barack Obama (Demo - Fallback Data)'\n        session['source_breakdown'] = [\n            {'source': 'Wikipedia', 'word_count': 1500, 'url': 'https://en.wikipedia.org/wiki/Barack_Obama'},\n            {'source': 'Sample Speech', 'word_count': 3500, 'url': 'Demo Data'}\n        ]\n        \n        return render_template('results.html',\n                             results=demo_results,\n                             politician_name='Barack Obama (Demo - Fallback Data)',\n                             source_breakdown=session['source_breakdown'],\n                             demo_mode=True)\n\nif __name__ == '__main__':\n    app.run(host='0.0.0.0', port=5000, debug=True)\n","size_bytes":18912},"main.py":{"content":"from app import app\n\nif __name__ == '__main__':\n    app.run(host='0.0.0.0', port=5000, debug=True)\n","size_bytes":99},"models.py":{"content":"from app import db\nfrom datetime import datetime\n\nclass Feedback(db.Model):\n    id = db.Column(db.Integer, primary_key=True)\n    session_id = db.Column(db.String(36), nullable=False)\n    politician_name = db.Column(db.String(200), nullable=False)\n    rating = db.Column(db.Integer)  # 1-5 stars\n    comments = db.Column(db.Text)\n    helpful = db.Column(db.Boolean)\n    timestamp = db.Column(db.DateTime, default=datetime.utcnow)\n    \n    def __repr__(self):\n        return f'<Feedback {self.politician_name}: {self.rating}/5>'\n\nclass AnalysisSession(db.Model):\n    id = db.Column(db.Integer, primary_key=True)\n    session_id = db.Column(db.String(36), unique=True, nullable=False)\n    politician_name = db.Column(db.String(200), nullable=False)\n    country = db.Column(db.String(100))\n    analysis_types = db.Column(db.Text)  # JSON string\n    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n    completed_at = db.Column(db.DateTime)\n    status = db.Column(db.String(50), default='started')\n    \n    def __repr__(self):\n        return f'<AnalysisSession {self.politician_name}: {self.status}>'\n","size_bytes":1107},"pyproject.toml":{"content":"[project]\nname = \"repl-nix-workspace\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nrequires-python = \">=3.11\"\ndependencies = [\n    \"beautifulsoup4>=4.13.5\",\n    \"email-validator>=2.3.0\",\n    \"feedparser>=6.0.11\",\n    \"flask>=3.1.2\",\n    \"flask-sqlalchemy>=3.1.1\",\n    \"gunicorn>=23.0.0\",\n    \"matplotlib>=3.10.6\",\n    \"nltk>=3.9.1\",\n    \"pandas>=2.3.2\",\n    \"plotly>=6.3.0\",\n    \"psycopg2-binary>=2.9.10\",\n    \"requests>=2.32.5\",\n    \"scikit-learn>=1.7.1\",\n    \"spacy>=3.8.7\",\n    \"sqlalchemy>=2.0.43\",\n    \"textblob>=0.19.0\",\n    \"trafilatura>=2.0.0\",\n    \"werkzeug>=3.1.3\",\n    \"wordcloud>=1.9.4\",\n]\n","size_bytes":617},"replit.md":{"content":"# Political Discourse Analyzer\n\n## Overview\n\nThe Political Discourse Analyzer is a comprehensive web application that performs automated analysis of political speeches and texts using advanced natural language processing (NLP) techniques. The system allows users to input a politician's name, automatically collects relevant texts from multiple sources, and provides detailed discourse analysis across multiple dimensions including rhetorical analysis, sentiment evolution, topic modeling, and persuasion techniques.\n\n## User Preferences\n\nPreferred communication style: Simple, everyday language.\n\n## System Architecture\n\n### Frontend Architecture\n- **Template Engine**: Jinja2 templates with Bootstrap 5 for responsive UI\n- **Client-Side**: Vanilla JavaScript with progressive enhancement\n- **Visualization**: Plotly.js for interactive charts and data visualization\n- **UI Framework**: Bootstrap 5 with custom CSS for academic styling\n- **Real-time Updates**: JavaScript-based progress tracking and status updates\n\n### Backend Architecture\n- **Web Framework**: Flask with SQLAlchemy ORM for database operations\n- **Application Pattern**: Blueprint-based modular architecture with separation of concerns\n- **Session Management**: Flask sessions for tracking analysis progress and user interactions\n- **Error Handling**: Centralized logging with graceful error recovery\n\n### Data Processing Pipeline\n- **Text Collection**: Multi-source scraping system using requests, BeautifulSoup, and trafilatura\n- **NLP Processing**: spaCy and NLTK for linguistic analysis and text processing\n- **Analysis Engine**: Custom PoliticalAnalyzer class implementing multiple discourse analysis methods\n- **Data Validation**: Input sanitization and content filtering for reliable analysis\n\n### Database Design\n- **ORM**: SQLAlchemy with declarative base models\n- **Session Tracking**: AnalysisSession model for persistent analysis state\n- **User Feedback**: Feedback model for collecting user ratings and comments\n- **Database Flexibility**: Configurable database URI supporting SQLite for development\n\n### Analysis Components\n- **Rhetorical Analysis**: Ethos, pathos, logos identification using keyword matching\n- **Sentiment Analysis**: TextBlob integration for emotional tone tracking\n- **Topic Modeling**: Pattern recognition for theme identification\n- **Linguistic Features**: Readability scores and complexity metrics\n- **Visualization**: Plotly integration for interactive result presentation\n\n## External Dependencies\n\n### NLP Libraries\n- **spaCy**: Core NLP processing with en_core_web_sm model\n- **NLTK**: Text tokenization, POS tagging, and stopwords\n- **TextBlob**: Sentiment analysis and basic text processing\n\n### Web Scraping\n- **requests**: HTTP client for web requests\n- **BeautifulSoup**: HTML parsing and content extraction\n- **trafilatura**: Optimized text extraction from web pages\n- **feedparser**: RSS/Atom feed processing for news sources\n\n### Data Sources\n- **Wikipedia API**: Biographical information and political content\n- **Government Websites**: Official political documents and speeches\n- **News APIs**: Real-time political content from major news outlets\n- **YouTube**: Transcript extraction for video content analysis\n\n### Visualization and UI\n- **Plotly.js**: Interactive charts and data visualization\n- **Bootstrap 5**: Responsive CSS framework\n- **Font Awesome**: Icon library for enhanced UI\n- **Chart.js**: Additional charting capabilities for analysis results\n\n### Infrastructure\n- **Flask-SQLAlchemy**: Database ORM and migrations\n- **Werkzeug**: WSGI utilities and development server\n- **ProxyFix**: Production deployment with reverse proxy support","size_bytes":3668},"scraper.py":{"content":"import requests\nfrom bs4 import BeautifulSoup\nimport time\nimport logging\nfrom urllib.parse import urljoin, urlparse\nimport trafilatura\nimport feedparser\nfrom typing import List, Dict\n\nclass PoliticalTextScraper:\n    def __init__(self):\n        self.session = requests.Session()\n        self.session.headers.update({\n            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n        })\n        self.rate_limit_delay = 2  # seconds between requests\n\n    def get_website_text_content(self, url: str) -> str:\n        \"\"\"Extract main text content from a website using trafilatura\"\"\"\n        try:\n            downloaded = trafilatura.fetch_url(url)\n            if downloaded:\n                text = trafilatura.extract(downloaded)\n                return text or \"\"\n            return \"\"\n        except Exception as e:\n            logging.error(f\"Error extracting content from {url}: {str(e)}\")\n            return \"\"\n\n    def search_wikipedia(self, politician_name: str) -> Dict:\n        \"\"\"Search Wikipedia for politician information\"\"\"\n        try:\n            # Wikipedia search API\n            search_url = \"https://en.wikipedia.org/api/rest_v1/page/summary/{}\"\n            formatted_name = politician_name.replace(' ', '_')\n            \n            response = self.session.get(search_url.format(formatted_name))\n            time.sleep(self.rate_limit_delay)\n            \n            if response.status_code == 200:\n                data = response.json()\n                # Get full page content\n                page_url = f\"https://en.wikipedia.org/wiki/{formatted_name}\"\n                full_text = self.get_website_text_content(page_url)\n                \n                return {\n                    'source': 'Wikipedia',\n                    'title': data.get('title', politician_name),\n                    'content': full_text[:5000] if full_text else data.get('extract', ''),\n                    'url': page_url,\n                    'word_count': len(full_text.split()) if full_text else 0\n                }\n        except Exception as e:\n            logging.error(f\"Error searching Wikipedia for {politician_name}: {str(e)}\")\n            return None\n\n    def search_news_sources(self, politician_name: str) -> List[Dict]:\n        \"\"\"Search basic news sources\"\"\"\n        news_results = []\n        \n        # BBC News search (using their search page)\n        try:\n            bbc_search_url = f\"https://www.bbc.com/search?q={politician_name.replace(' ', '+')}\"\n            bbc_content = self.get_website_text_content(bbc_search_url)\n            if bbc_content:\n                news_results.append({\n                    'source': 'BBC News Search',\n                    'content': bbc_content[:2000],\n                    'url': bbc_search_url,\n                    'word_count': len(bbc_content.split())\n                })\n        except Exception as e:\n            logging.error(f\"Error searching BBC: {str(e)}\")\n        \n        time.sleep(self.rate_limit_delay)\n        \n        # Reuters search\n        try:\n            reuters_search_url = f\"https://www.reuters.com/site-search/?query={politician_name.replace(' ', '+')}\"\n            reuters_content = self.get_website_text_content(reuters_search_url)\n            if reuters_content:\n                news_results.append({\n                    'source': 'Reuters Search',\n                    'content': reuters_content[:2000],\n                    'url': reuters_search_url,\n                    'word_count': len(reuters_content.split())\n                })\n        except Exception as e:\n            logging.error(f\"Error searching Reuters: {str(e)}\")\n        \n        return news_results\n\n    def search_government_sources(self, politician_name: str, country: str = '') -> List[Dict]:\n        \"\"\"Search government websites for politician information\"\"\"\n        gov_results = []\n        \n        # US Congress search\n        if country.lower() in ['usa', 'us', 'united states', ''] or 'america' in country.lower():\n            try:\n                congress_search_url = f\"https://www.congress.gov/search?q={politician_name.replace(' ', '+')}\"\n                congress_content = self.get_website_text_content(congress_search_url)\n                if congress_content:\n                    gov_results.append({\n                        'source': 'US Congress',\n                        'content': congress_content[:2000],\n                        'url': congress_search_url,\n                        'word_count': len(congress_content.split())\n                    })\n            except Exception as e:\n                logging.error(f\"Error searching Congress.gov: {str(e)}\")\n        \n        time.sleep(self.rate_limit_delay)\n        \n        # UK Parliament search\n        if country.lower() in ['uk', 'united kingdom', 'britain', 'england']:\n            try:\n                parliament_search_url = f\"https://www.parliament.uk/search/results/?q={politician_name.replace(' ', '+')}\"\n                parliament_content = self.get_website_text_content(parliament_search_url)\n                if parliament_content:\n                    gov_results.append({\n                        'source': 'UK Parliament',\n                        'content': parliament_content[:2000],\n                        'url': parliament_search_url,\n                        'word_count': len(parliament_content.split())\n                    })\n            except Exception as e:\n                logging.error(f\"Error searching Parliament.uk: {str(e)}\")\n        \n        return gov_results\n\n    def collect_texts(self, politician_name: str, country: str = '') -> List[Dict]:\n        \"\"\"Main function to collect texts from various sources\"\"\"\n        all_texts = []\n        \n        logging.info(f\"Starting text collection for: {politician_name}\")\n        \n        # Search Wikipedia\n        wiki_result = self.search_wikipedia(politician_name)\n        if wiki_result:\n            all_texts.append(wiki_result)\n        \n        # Search news sources\n        news_results = self.search_news_sources(politician_name)\n        all_texts.extend(news_results)\n        \n        # Search government sources\n        gov_results = self.search_government_sources(politician_name, country)\n        all_texts.extend(gov_results)\n        \n        # Filter out empty results\n        all_texts = [text for text in all_texts if text.get('content', '').strip()]\n        \n        logging.info(f\"Collected {len(all_texts)} text sources\")\n        \n        return all_texts\n\n    def get_sample_texts(self, politician_name: str) -> List[Dict]:\n        \"\"\"Get sample texts for demo purposes\"\"\"\n        sample_texts = {\n            'Barack Obama': [\n                {\n                    'source': 'Sample Speech',\n                    'content': 'Yes we can. That was the call to action that brought us together. Hope over fear, unity over division, sending a message that change has come to America. We are the ones we have been waiting for.',\n                    'url': 'sample_data',\n                    'word_count': 42\n                }\n            ],\n            'Winston Churchill': [\n                {\n                    'source': 'Sample Speech', \n                    'content': 'We shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and in the streets, we shall fight in the hills; we shall never surrender.',\n                    'url': 'sample_data',\n                    'word_count': 32\n                }\n            ]\n        }\n        \n        return sample_texts.get(politician_name, [])\n","size_bytes":7619},"static/css/style.css":{"content":"/* Political Discourse Analyzer - Custom Styles */\n\n:root {\n    --primary-color: #0056b3;\n    --secondary-color: #6c757d;\n    --success-color: #28a745;\n    --danger-color: #dc3545;\n    --warning-color: #ffc107;\n    --info-color: #17a2b8;\n    --light-color: #f8f9fa;\n    --dark-color: #343a40;\n    --academic-blue: #1e3a8a;\n    --academic-gray: #374151;\n}\n\n/* Base Styles */\nbody {\n    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n    line-height: 1.6;\n    color: var(--academic-gray);\n    background-color: #f5f7fa;\n}\n\n/* Navigation */\n.navbar {\n    box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n}\n\n.navbar-brand {\n    font-weight: 600;\n    font-size: 1.3rem;\n}\n\n/* Cards */\n.card {\n    border: none;\n    border-radius: 12px;\n    box-shadow: 0 2px 20px rgba(0,0,0,0.1);\n    transition: transform 0.2s ease, box-shadow 0.2s ease;\n}\n\n.card:hover {\n    transform: translateY(-2px);\n    box-shadow: 0 4px 25px rgba(0,0,0,0.15);\n}\n\n.card-header {\n    border-radius: 12px 12px 0 0 !important;\n    border-bottom: 1px solid rgba(255,255,255,0.1);\n    font-weight: 600;\n}\n\n/* Forms */\n.form-control, .form-select {\n    border-radius: 8px;\n    border: 2px solid #e9ecef;\n    transition: border-color 0.15s ease, box-shadow 0.15s ease;\n}\n\n.form-control:focus, .form-select:focus {\n    border-color: var(--primary-color);\n    box-shadow: 0 0 0 0.2rem rgba(0, 86, 179, 0.25);\n}\n\n.form-check-input:checked {\n    background-color: var(--primary-color);\n    border-color: var(--primary-color);\n}\n\n/* Buttons */\n.btn {\n    border-radius: 8px;\n    font-weight: 500;\n    padding: 0.5rem 1.5rem;\n    transition: all 0.15s ease;\n}\n\n.btn-primary {\n    background-color: var(--primary-color);\n    border-color: var(--primary-color);\n}\n\n.btn-primary:hover {\n    background-color: #004085;\n    border-color: #004085;\n    transform: translateY(-1px);\n}\n\n.btn-lg {\n    padding: 0.75rem 2rem;\n    font-size: 1.1rem;\n}\n\n/* Progress Bars */\n.progress {\n    height: 8px;\n    border-radius: 10px;\n    background-color: rgba(0,0,0,0.1);\n}\n\n.progress-bar {\n    border-radius: 10px;\n    background: linear-gradient(90deg, var(--primary-color), var(--info-color));\n}\n\n/* Analysis Cards */\n.analysis-card {\n    transition: all 0.3s ease;\n}\n\n.analysis-card.border-success {\n    border: 2px solid var(--success-color) !important;\n    background: linear-gradient(135deg, #f8fff9, #ffffff);\n}\n\n.analysis-card.border-danger {\n    border: 2px solid var(--danger-color) !important;\n    background: linear-gradient(135deg, #fff8f8, #ffffff);\n}\n\n/* Tabs */\n.nav-tabs {\n    border-bottom: 2px solid var(--primary-color);\n}\n\n.nav-tabs .nav-link {\n    border: none;\n    color: var(--academic-gray);\n    font-weight: 500;\n    padding: 0.75rem 1.5rem;\n    border-radius: 8px 8px 0 0;\n    transition: all 0.15s ease;\n}\n\n.nav-tabs .nav-link:hover {\n    background-color: rgba(0, 86, 179, 0.1);\n    color: var(--primary-color);\n}\n\n.nav-tabs .nav-link.active {\n    background-color: var(--primary-color);\n    color: white;\n    border: none;\n}\n\n.tab-content {\n    background: white;\n    border-radius: 0 0 12px 12px;\n    min-height: 400px;\n}\n\n/* Badges */\n.badge {\n    font-weight: 500;\n    padding: 0.5em 0.75em;\n    border-radius: 6px;\n}\n\n.badge.fs-6 {\n    font-size: 1rem !important;\n    padding: 0.6em 1em;\n}\n\n/* Rating System */\n.rating-container .btn-check:checked + .btn {\n    background-color: var(--warning-color);\n    border-color: var(--warning-color);\n    color: #000;\n}\n\n.rating-container .btn:hover {\n    background-color: rgba(255, 193, 7, 0.2);\n    border-color: var(--warning-color);\n}\n\n/* Tables */\n.table {\n    border-radius: 8px;\n    overflow: hidden;\n}\n\n.table thead th {\n    background-color: var(--primary-color);\n    color: white;\n    border: none;\n    font-weight: 600;\n}\n\n.table-hover tbody tr:hover {\n    background-color: rgba(0, 86, 179, 0.05);\n}\n\n/* Alerts */\n.alert {\n    border-radius: 8px;\n    border: none;\n    font-weight: 500;\n}\n\n.alert-info {\n    background: linear-gradient(135deg, #e8f4fd, #f0f9ff);\n    color: #0c5460;\n}\n\n.alert-warning {\n    background: linear-gradient(135deg, #fff8e1, #fffbf0);\n    color: #856404;\n}\n\n.alert-success {\n    background: linear-gradient(135deg, #e8f5e8, #f0fff0);\n    color: #155724;\n}\n\n/* Loading Animations */\n@keyframes pulse {\n    0% { opacity: 1; }\n    50% { opacity: 0.5; }\n    100% { opacity: 1; }\n}\n\n.loading {\n    animation: pulse 1.5s infinite;\n}\n\n/* Chart Containers */\n.chart-container {\n    background: white;\n    border-radius: 8px;\n    padding: 1rem;\n    box-shadow: 0 2px 10px rgba(0,0,0,0.05);\n}\n\n/* Footer */\nfooter {\n    margin-top: auto;\n    background: linear-gradient(135deg, #f8f9fa, #e9ecef);\n    border-top: 1px solid #dee2e6;\n}\n\n/* Responsive Design */\n@media (max-width: 768px) {\n    .display-4 {\n        font-size: 2rem;\n    }\n    \n    .display-5 {\n        font-size: 1.75rem;\n    }\n    \n    .btn-group .btn {\n        font-size: 0.875rem;\n        padding: 0.375rem 0.75rem;\n    }\n    \n    .card-body {\n        padding: 1rem;\n    }\n    \n    .nav-tabs .nav-link {\n        font-size: 0.875rem;\n        padding: 0.5rem 1rem;\n    }\n}\n\n/* Academic Style Enhancements */\n.academic-header {\n    background: linear-gradient(135deg, var(--academic-blue), var(--primary-color));\n    color: white;\n    padding: 2rem 0;\n    margin-bottom: 2rem;\n}\n\n.citation-note {\n    font-style: italic;\n    font-size: 0.9rem;\n    color: var(--academic-gray);\n    border-left: 3px solid var(--primary-color);\n    padding-left: 1rem;\n    margin: 1rem 0;\n}\n\n/* Interactive Elements */\n.clickable {\n    cursor: pointer;\n    transition: all 0.15s ease;\n}\n\n.clickable:hover {\n    transform: translateY(-1px);\n    opacity: 0.8;\n}\n\n/* Word Cloud Styling */\n.word-cloud-container {\n    background: linear-gradient(135deg, #f8f9fa, #ffffff);\n    border-radius: 12px;\n    padding: 2rem;\n    text-align: center;\n    min-height: 300px;\n    display: flex;\n    align-items: center;\n    justify-content: center;\n}\n\n/* Analysis Results Styling */\n.analysis-metric {\n    background: linear-gradient(135deg, #ffffff, #f8f9fa);\n    border-radius: 8px;\n    padding: 1rem;\n    text-align: center;\n    border: 1px solid #e9ecef;\n}\n\n.analysis-metric h3 {\n    margin-bottom: 0.5rem;\n    font-weight: 600;\n}\n\n.analysis-metric p {\n    margin-bottom: 0;\n    color: var(--academic-gray);\n    font-size: 0.9rem;\n}\n\n/* Politician Suggestion Badges */\n.politician-suggestion {\n    background-color: transparent !important;\n    border: 1px solid var(--primary-color) !important;\n    color: var(--primary-color) !important;\n    cursor: pointer;\n    transition: all 0.2s ease;\n    font-weight: 500;\n    padding: 0.4rem 0.8rem;\n    margin: 0.2rem;\n    display: inline-block;\n    border-radius: 6px;\n}\n\n.politician-suggestion:hover {\n    background-color: var(--primary-color) !important;\n    color: white !important;\n    transform: translateY(-1px);\n    box-shadow: 0 2px 8px rgba(0, 86, 179, 0.3);\n}\n\n/* Custom Scrollbar */\n::-webkit-scrollbar {\n    width: 8px;\n}\n\n::-webkit-scrollbar-track {\n    background: #f1f1f1;\n    border-radius: 4px;\n}\n\n::-webkit-scrollbar-thumb {\n    background: var(--primary-color);\n    border-radius: 4px;\n}\n\n::-webkit-scrollbar-thumb:hover {\n    background: #004085;\n}\n","size_bytes":7192},"static/js/main.js":{"content":"/**\n * Political Discourse Analyzer - Main JavaScript\n * Provides interactive functionality and UI enhancements\n */\n\ndocument.addEventListener('DOMContentLoaded', function() {\n    initializeApp();\n});\n\n/**\n * Initialize the application\n */\nfunction initializeApp() {\n    setupFormValidation();\n    setupInteractiveElements();\n    setupTooltips();\n    setupAnimations();\n    setupAccessibility();\n}\n\n/**\n * Setup form validation and enhancements\n */\nfunction setupFormValidation() {\n    // Enhanced form validation for politician name input\n    const politicianNameInput = document.getElementById('politician_name');\n    if (politicianNameInput) {\n        politicianNameInput.addEventListener('input', function() {\n            validatePoliticianName(this);\n        });\n        \n        politicianNameInput.addEventListener('blur', function() {\n            validatePoliticianName(this, true);\n        });\n    }\n    \n    // Analysis form validation\n    const analysisForm = document.getElementById('analysisForm');\n    if (analysisForm) {\n        analysisForm.addEventListener('submit', function(e) {\n            if (!validateAnalysisForm(this)) {\n                e.preventDefault();\n                return false;\n            }\n        });\n    }\n    \n    // Real-time checkbox validation\n    const analysisCheckboxes = document.querySelectorAll('input[name=\"analysis_types\"]');\n    analysisCheckboxes.forEach(checkbox => {\n        checkbox.addEventListener('change', function() {\n            validateAnalysisTypes();\n        });\n    });\n}\n\n/**\n * Validate politician name input\n */\nfunction validatePoliticianName(input, showFeedback = false) {\n    const value = input.value.trim();\n    const isValid = /^[A-Za-z\\s\\-\\.']+$/.test(value) && value.length >= 2;\n    \n    // Remove existing validation classes\n    input.classList.remove('is-valid', 'is-invalid');\n    \n    // Remove existing feedback\n    const existingFeedback = input.parentNode.querySelector('.invalid-feedback, .valid-feedback');\n    if (existingFeedback) {\n        existingFeedback.remove();\n    }\n    \n    if (value.length > 0) {\n        if (isValid) {\n            input.classList.add('is-valid');\n            if (showFeedback) {\n                showInputFeedback(input, 'Valid politician name', 'valid');\n            }\n        } else {\n            input.classList.add('is-invalid');\n            if (showFeedback) {\n                showInputFeedback(input, 'Please enter a valid name (letters, spaces, hyphens, periods, and apostrophes only)', 'invalid');\n            }\n        }\n    }\n    \n    return isValid;\n}\n\n/**\n * Validate analysis types selection\n */\nfunction validateAnalysisTypes() {\n    const checkboxes = document.querySelectorAll('input[name=\"analysis_types\"]:checked');\n    const isValid = checkboxes.length > 0;\n    \n    const container = document.querySelector('.analysis-types-container') || \n                     document.querySelector('input[name=\"analysis_types\"]').closest('.mb-4');\n    \n    // Remove existing validation feedback\n    const existingAlert = container.querySelector('.analysis-validation-alert');\n    if (existingAlert) {\n        existingAlert.remove();\n    }\n    \n    if (!isValid) {\n        const alert = document.createElement('div');\n        alert.className = 'alert alert-warning analysis-validation-alert mt-2';\n        alert.innerHTML = '<i class=\"fas fa-exclamation-triangle me-2\"></i>Please select at least one analysis type.';\n        container.appendChild(alert);\n    }\n    \n    return isValid;\n}\n\n/**\n * Validate entire analysis form\n */\nfunction validateAnalysisForm(form) {\n    const politicianName = form.querySelector('#politician_name');\n    const analysisTypes = form.querySelectorAll('input[name=\"analysis_types\"]:checked');\n    \n    let isValid = true;\n    \n    // Validate politician name\n    if (!validatePoliticianName(politicianName, true)) {\n        isValid = false;\n    }\n    \n    // Validate analysis types\n    if (!validateAnalysisTypes()) {\n        isValid = false;\n    }\n    \n    return isValid;\n}\n\n/**\n * Show input validation feedback\n */\nfunction showInputFeedback(input, message, type) {\n    const feedback = document.createElement('div');\n    feedback.className = `${type}-feedback`;\n    feedback.textContent = message;\n    input.parentNode.appendChild(feedback);\n}\n\n/**\n * Setup interactive elements\n */\nfunction setupInteractiveElements() {\n    // Sample politician selection\n    setupSamplePoliticianSelection();\n    \n    // Copy to clipboard functionality\n    setupCopyToClipboard();\n    \n    // Progress animation helpers\n    setupProgressAnimations();\n    \n    // Card hover effects\n    setupCardHoverEffects();\n    \n    // Smooth scrolling\n    setupSmoothScrolling();\n}\n\n/**\n * Setup sample politician quick-select functionality\n */\nfunction setupSamplePoliticianSelection() {\n    const samplePoliticians = document.querySelectorAll('.list-unstyled li');\n    \n    samplePoliticians.forEach(item => {\n        if (item.textContent.trim()) {\n            item.style.cursor = 'pointer';\n            item.classList.add('clickable');\n            \n            // Add hover effect\n            item.addEventListener('mouseenter', function() {\n                this.style.backgroundColor = 'rgba(0, 86, 179, 0.1)';\n                this.style.borderRadius = '6px';\n                this.style.padding = '0.25rem 0.5rem';\n            });\n            \n            item.addEventListener('mouseleave', function() {\n                this.style.backgroundColor = '';\n                this.style.padding = '';\n            });\n            \n            // Add click functionality\n            item.addEventListener('click', function() {\n                const name = this.textContent.trim();\n                const nameInput = document.getElementById('politician_name');\n                const countrySelect = document.getElementById('country');\n                \n                if (nameInput) {\n                    nameInput.value = name;\n                    validatePoliticianName(nameInput);\n                    \n                    // Add visual feedback\n                    nameInput.style.backgroundColor = '#d4edda';\n                    setTimeout(() => {\n                        nameInput.style.backgroundColor = '';\n                    }, 1000);\n                }\n                \n                // Set appropriate country\n                if (countrySelect) {\n                    const countryMappings = {\n                        'Barack Obama': 'USA',\n                        'Joe Biden': 'USA',\n                        'Donald Trump': 'USA',\n                        'Hillary Clinton': 'USA',\n                        'Winston Churchill': 'UK',\n                        'Angela Merkel': 'Germany',\n                        'Justin Trudeau': 'Canada',\n                        'Emmanuel Macron': 'France'\n                    };\n                    \n                    const country = countryMappings[name];\n                    if (country) {\n                        countrySelect.value = country;\n                    }\n                }\n                \n                // Show success message\n                showTemporaryMessage('Politician selected: ' + name, 'success');\n            });\n        }\n    });\n}\n\n/**\n * Setup copy to clipboard functionality\n */\nfunction setupCopyToClipboard() {\n    // Add copy buttons to code blocks or data sections\n    const copyableElements = document.querySelectorAll('[data-copyable]');\n    \n    copyableElements.forEach(element => {\n        const copyBtn = document.createElement('button');\n        copyBtn.className = 'btn btn-sm btn-outline-secondary position-absolute top-0 end-0 m-2';\n        copyBtn.innerHTML = '<i class=\"fas fa-copy\"></i>';\n        copyBtn.style.zIndex = '10';\n        \n        element.style.position = 'relative';\n        element.appendChild(copyBtn);\n        \n        copyBtn.addEventListener('click', function() {\n            const text = element.textContent || element.innerText;\n            navigator.clipboard.writeText(text).then(() => {\n                this.innerHTML = '<i class=\"fas fa-check\"></i>';\n                setTimeout(() => {\n                    this.innerHTML = '<i class=\"fas fa-copy\"></i>';\n                }, 2000);\n            });\n        });\n    });\n}\n\n/**\n * Setup progress animations\n */\nfunction setupProgressAnimations() {\n    const progressBars = document.querySelectorAll('.progress-bar');\n    \n    progressBars.forEach(bar => {\n        const originalWidth = bar.style.width;\n        bar.style.width = '0%';\n        \n        setTimeout(() => {\n            bar.style.transition = 'width 1s ease-in-out';\n            bar.style.width = originalWidth;\n        }, 100);\n    });\n}\n\n/**\n * Setup card hover effects\n */\nfunction setupCardHoverEffects() {\n    const cards = document.querySelectorAll('.card');\n    \n    cards.forEach(card => {\n        card.addEventListener('mouseenter', function() {\n            this.style.transform = 'translateY(-2px)';\n            this.style.boxShadow = '0 4px 25px rgba(0,0,0,0.15)';\n        });\n        \n        card.addEventListener('mouseleave', function() {\n            this.style.transform = '';\n            this.style.boxShadow = '';\n        });\n    });\n}\n\n/**\n * Setup smooth scrolling\n */\nfunction setupSmoothScrolling() {\n    const links = document.querySelectorAll('a[href^=\"#\"]');\n    \n    links.forEach(link => {\n        link.addEventListener('click', function(e) {\n            const targetId = this.getAttribute('href').substring(1);\n            const targetElement = document.getElementById(targetId);\n            \n            if (targetElement) {\n                e.preventDefault();\n                targetElement.scrollIntoView({\n                    behavior: 'smooth',\n                    block: 'start'\n                });\n            }\n        });\n    });\n}\n\n/**\n * Setup tooltips\n */\nfunction setupTooltips() {\n    // Initialize Bootstrap tooltips if available\n    if (typeof bootstrap !== 'undefined' && bootstrap.Tooltip) {\n        const tooltipTriggerList = [].slice.call(document.querySelectorAll('[data-bs-toggle=\"tooltip\"]'));\n        tooltipTriggerList.map(function(tooltipTriggerEl) {\n            return new bootstrap.Tooltip(tooltipTriggerEl);\n        });\n    }\n    \n    // Custom tooltips for form elements\n    const formInputs = document.querySelectorAll('input, select, textarea');\n    formInputs.forEach(input => {\n        if (input.title) {\n            input.addEventListener('focus', function() {\n                showTooltip(this, this.title);\n            });\n            \n            input.addEventListener('blur', function() {\n                hideTooltip(this);\n            });\n        }\n    });\n}\n\n/**\n * Show custom tooltip\n */\nfunction showTooltip(element, text) {\n    const tooltip = document.createElement('div');\n    tooltip.className = 'custom-tooltip';\n    tooltip.textContent = text;\n    tooltip.style.cssText = `\n        position: absolute;\n        background: #333;\n        color: white;\n        padding: 0.5rem;\n        border-radius: 4px;\n        font-size: 0.875rem;\n        z-index: 1000;\n        pointer-events: none;\n        opacity: 0;\n        transition: opacity 0.3s ease;\n    `;\n    \n    document.body.appendChild(tooltip);\n    \n    const rect = element.getBoundingClientRect();\n    tooltip.style.left = rect.left + 'px';\n    tooltip.style.top = (rect.bottom + 5) + 'px';\n    \n    setTimeout(() => {\n        tooltip.style.opacity = '1';\n    }, 100);\n    \n    element._tooltip = tooltip;\n}\n\n/**\n * Hide custom tooltip\n */\nfunction hideTooltip(element) {\n    if (element._tooltip) {\n        element._tooltip.style.opacity = '0';\n        setTimeout(() => {\n            if (element._tooltip && element._tooltip.parentNode) {\n                element._tooltip.parentNode.removeChild(element._tooltip);\n            }\n            element._tooltip = null;\n        }, 300);\n    }\n}\n\n/**\n * Setup animations\n */\nfunction setupAnimations() {\n    // Fade in animations for cards\n    const animatedElements = document.querySelectorAll('.card, .alert');\n    \n    animatedElements.forEach((element, index) => {\n        element.style.opacity = '0';\n        element.style.transform = 'translateY(20px)';\n        element.style.transition = 'opacity 0.6s ease, transform 0.6s ease';\n        \n        setTimeout(() => {\n            element.style.opacity = '1';\n            element.style.transform = 'translateY(0)';\n        }, index * 100);\n    });\n    \n    // Loading spinner animations\n    setupLoadingSpinners();\n}\n\n/**\n * Setup loading spinners\n */\nfunction setupLoadingSpinners() {\n    const spinners = document.querySelectorAll('.fa-spinner');\n    \n    spinners.forEach(spinner => {\n        spinner.style.animation = 'spin 1s linear infinite';\n    });\n    \n    // Add CSS for spin animation if not exists\n    if (!document.querySelector('#spin-animation-style')) {\n        const style = document.createElement('style');\n        style.id = 'spin-animation-style';\n        style.textContent = `\n            @keyframes spin {\n                0% { transform: rotate(0deg); }\n                100% { transform: rotate(360deg); }\n            }\n        `;\n        document.head.appendChild(style);\n    }\n}\n\n/**\n * Setup accessibility enhancements\n */\nfunction setupAccessibility() {\n    // Add ARIA labels to interactive elements\n    const interactiveElements = document.querySelectorAll('.clickable, button, [role=\"button\"]');\n    \n    interactiveElements.forEach(element => {\n        if (!element.getAttribute('aria-label') && !element.getAttribute('aria-labelledby')) {\n            const text = element.textContent || element.title || 'Interactive element';\n            element.setAttribute('aria-label', text.trim());\n        }\n    });\n    \n    // Keyboard navigation for custom interactive elements\n    const customInteractives = document.querySelectorAll('.clickable');\n    customInteractives.forEach(element => {\n        if (!element.hasAttribute('tabindex')) {\n            element.setAttribute('tabindex', '0');\n        }\n        \n        element.addEventListener('keydown', function(e) {\n            if (e.key === 'Enter' || e.key === ' ') {\n                e.preventDefault();\n                this.click();\n            }\n        });\n    });\n    \n    // Focus management\n    setupFocusManagement();\n}\n\n/**\n * Setup focus management\n */\nfunction setupFocusManagement() {\n    // Focus trap for modals\n    const modals = document.querySelectorAll('.modal');\n    modals.forEach(modal => {\n        modal.addEventListener('shown.bs.modal', function() {\n            const focusableElements = this.querySelectorAll('button, input, select, textarea, [tabindex]:not([tabindex=\"-1\"])');\n            if (focusableElements.length > 0) {\n                focusableElements[0].focus();\n            }\n        });\n    });\n    \n    // Skip link functionality\n    const skipLink = document.querySelector('.skip-link');\n    if (skipLink) {\n        skipLink.addEventListener('click', function(e) {\n            e.preventDefault();\n            const target = document.querySelector(this.getAttribute('href'));\n            if (target) {\n                target.focus();\n                target.scrollIntoView();\n            }\n        });\n    }\n}\n\n/**\n * Utility Functions\n */\n\n/**\n * Show temporary message\n */\nfunction showTemporaryMessage(message, type = 'info', duration = 3000) {\n    const alertDiv = document.createElement('div');\n    alertDiv.className = `alert alert-${type} alert-dismissible fade show position-fixed`;\n    alertDiv.style.cssText = `\n        top: 20px;\n        right: 20px;\n        z-index: 1050;\n        min-width: 300px;\n    `;\n    \n    alertDiv.innerHTML = `\n        <i class=\"fas fa-${type === 'success' ? 'check' : type === 'warning' ? 'exclamation-triangle' : 'info'} me-2\"></i>\n        ${message}\n        <button type=\"button\" class=\"btn-close\" data-bs-dismiss=\"alert\"></button>\n    `;\n    \n    document.body.appendChild(alertDiv);\n    \n    // Auto-dismiss after duration\n    setTimeout(() => {\n        if (alertDiv.parentNode) {\n            alertDiv.classList.remove('show');\n            setTimeout(() => {\n                if (alertDiv.parentNode) {\n                    alertDiv.parentNode.removeChild(alertDiv);\n                }\n            }, 300);\n        }\n    }, duration);\n}\n\n/**\n * Format numbers with commas\n */\nfunction formatNumber(num) {\n    return num.toString().replace(/\\B(?=(\\d{3})+(?!\\d))/g, ',');\n}\n\n/**\n * Debounce function\n */\nfunction debounce(func, wait) {\n    let timeout;\n    return function executedFunction(...args) {\n        const later = () => {\n            clearTimeout(timeout);\n            func(...args);\n        };\n        clearTimeout(timeout);\n        timeout = setTimeout(later, wait);\n    };\n}\n\n/**\n * Throttle function\n */\nfunction throttle(func, limit) {\n    let inThrottle;\n    return function() {\n        const args = arguments;\n        const context = this;\n        if (!inThrottle) {\n            func.apply(context, args);\n            inThrottle = true;\n            setTimeout(() => inThrottle = false, limit);\n        }\n    };\n}\n\n/**\n * Check if element is in viewport\n */\nfunction isInViewport(element) {\n    const rect = element.getBoundingClientRect();\n    return (\n        rect.top >= 0 &&\n        rect.left >= 0 &&\n        rect.bottom <= (window.innerHeight || document.documentElement.clientHeight) &&\n        rect.right <= (window.innerWidth || document.documentElement.clientWidth)\n    );\n}\n\n/**\n * Animate elements when they come into view\n */\nfunction setupScrollAnimations() {\n    const animatedElements = document.querySelectorAll('.animate-on-scroll');\n    \n    const observer = new IntersectionObserver((entries) => {\n        entries.forEach(entry => {\n            if (entry.isIntersecting) {\n                entry.target.classList.add('animated');\n            }\n        });\n    }, {\n        threshold: 0.1\n    });\n    \n    animatedElements.forEach(element => {\n        observer.observe(element);\n    });\n}\n\n// Initialize scroll animations\ndocument.addEventListener('DOMContentLoaded', function() {\n    setupScrollAnimations();\n});\n\n// Export functions for use in other scripts\nwindow.PoliticalAnalyzer = {\n    showTemporaryMessage,\n    formatNumber,\n    debounce,\n    throttle,\n    isInViewport\n};\n","size_bytes":18247}},"version":1}